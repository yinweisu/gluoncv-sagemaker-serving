{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your algorithm on your local machine or on an Amazon SageMaker notebook instance\n",
    "\n",
    "While you're first packaging an algorithm use with Amazon SageMaker, you probably want to test it yourself to make sure it's working right. In the directory `container/local_test`, there is a framework for doing this. It includes three shell scripts for running and using the container and a directory structure that mimics the one outlined above.\n",
    "\n",
    "The scripts are:\n",
    "\n",
    "* `train_local.sh`: Run this with the name of the image and it will run training on the local tree. You'll want to modify the directory `test_dir/input/data/...` to be set up with the correct channels and data for your algorithm. Also, you'll want to modify the file `input/config/hyperparameters.json` to have the hyperparameter settings that you want to test (as strings).\n",
    "* `serve_local.sh`: Run this with the name of the image once you've trained the model and it should serve the model. It will run and wait for requests. Simply use the keyboard interrupt to stop it.\n",
    "* `predict.sh`: Run this with the name of a payload file and (optionally) the HTTP content type you want. The content type will default to `image/jpeg`. For example, you can run `$ ./predict.sh payload.jpg image/jpeg`.\n",
    "\n",
    "The directories as shipped are set up to test the image classification sample algorithm presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training, Batch Inference and Hosting your Algorithm in Amazon SageMaker\n",
    "\n",
    "Once you have your container packaged, you can use it to train and serve models. Let's do that with the algorithm we made above.\n",
    "\n",
    "## Set up the environment\n",
    "\n",
    "Here we specify a bucket to use and the role that will be used for working with Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "common_prefix = \"DEMO-gluoncv-model-zoo\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "\n",
    "The session remembers our connection parameters to Amazon SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "\n",
    "In order to use Amazon SageMaker to fit our algorithm, we'll create an `Estimator` that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "\n",
    "* The __container name__. This is constructed as in the shell commands above.\n",
    "* The __role__. As defined above.\n",
    "* The __instance count__ which is the number of machines to use for training.\n",
    "* The __instance type__ which is the type of machine to use for training.\n",
    "* The __output path__ determines where the model artifact will be written.\n",
    "* The __session__ is the SageMaker session object that we defined above.\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/gluoncv-image-classification:latest'.format(account, region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Location s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/training-input-data\n",
      "2020-05-04 21:33:27 Starting - Starting the training job...\n",
      "2020-05-04 21:33:29 Starting - Launching requested ML instances......\n",
      "2020-05-04 21:34:28 Starting - Preparing the instances for training...\n",
      "2020-05-04 21:35:24 Downloading - Downloading input data\n",
      "2020-05-04 21:35:24 Training - Downloading the training image...\n",
      "2020-05-04 21:35:57 Uploading - Uploading generated training model.\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mFilling weights from resnet18_v1b\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/models/resnet18_v1b-2d9d980c.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet18_v1b-2d9d980c.zip...\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/42432 [00:00<?, ?KB/s]#015 12%|#2        | 5283/42432 [00:00<00:00, 52822.49KB/s]#015 29%|##8       | 12277/42432 [00:00<00:00, 57007.96KB/s]#015 46%|####5     | 19474/42432 [00:00<00:00, 60798.83KB/s]#015 63%|######2   | 26729/42432 [00:00<00:00, 63901.94KB/s]#015 81%|########  | 34181/42432 [00:00<00:00, 66754.49KB/s]#015 99%|#########8| 41803/42432 [00:00<00:00, 69337.71KB/s]#01542433KB [00:00, 69724.40KB/s]                           \u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-05-04 21:36:08 Completed - Training job completed\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n"
     ]
    }
   ],
   "source": [
    "TRAINING_WORKDIR = \"data/training\"\n",
    "MODEL_NAME = 'resnet18_v1b'\n",
    "\n",
    "training_input = sess.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix)\n",
    "print (\"Training Data Location \" + training_input)\n",
    "classifier = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess,\n",
    "                       hyperparameters={'model_name': MODEL_NAME})\n",
    "classifier.fit(training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Transform\n",
    "Here we simply use a demo image for transform input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/batch-inference-input-data/cat1.jpg\n"
     ]
    }
   ],
   "source": [
    "TRANSFORM_WORKDIR = \"data/transform\"\n",
    "batch_inference_input_prefix = common_prefix + \"/batch-inference-input-data\"\n",
    "transform_input = sess.upload_data(TRANSFORM_WORKDIR, key_prefix=batch_inference_input_prefix) + \"/cat1.jpg\"\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model\n",
    "\n",
    "Deploying the model to Amazon SageMaker hosting just requires a `deploy` call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "# from sagemaker.predictor import csv_serializer\n",
    "\n",
    "model = classifier.create_model()\n",
    "predictor = classifier.deploy(1, 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose some data and use it for a prediction\n",
    "\n",
    "In order to do some predictions, we'll use a demo jpeg image to test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lynx], with probability 0.253.\n",
      "[Egyptian cat], with probability 0.252.\n",
      "[tiger cat], with probability 0.106.\n",
      "[tabby], with probability 0.063.\n",
      "[soft-coated wheaten terrier], with probability 0.041.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('data/transform/cat1.jpg', 'rb') as f:\n",
    "    x = f.read()\n",
    "    print(predictor.predict(x, initial_args={'ContentType':'image/jpeg'}).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint\n",
    "\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Package your resources as an Amazon SageMaker ModelPackage\n",
    "\n",
    "In this section, we will see how you can package your artifacts (ECR image and the trained artifact from your previous training job) into a ModelPackage. Once you complete this, you can list your product as a pretrained model in the AWS Marketplace.\n",
    "\n",
    "## Model Package Definition\n",
    "A Model Package is a reusable model artifacts abstraction that packages all ingredients necessary for inference. It consists of an inference specification that defines the inference image to use along with an optional model weights location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Region Limitation\n",
    "Seller onboarding is limited to us-east-2 region (CMH) only. The client we are creating below will be hard-coded to talk to our us-east-2 endpoint only. (Note: You may have previous done this step in Part 3. Repeating here to keep Part 4 self contained.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "smmp = boto3.client('sagemaker', region_name='us-west-2', endpoint_url=\"https://sagemaker.us-west-2.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Specification\n",
    "\n",
    "You specify details pertinent to your inference code in this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"InferenceSpecification\": {\n",
      "        \"Containers\": [\n",
      "            {\n",
      "                \"Image\": \"218569190993.dkr.ecr.us-west-2.amazonaws.com/gluoncv-image-classification:latest\",\n",
      "                \"ModelDataUrl\": \"s3://sagemaker-us-west-2-218569190993/output/gluoncv-image-classification-2020-05-04-21-33-26-992/output/model.tar.gz\"\n",
      "            }\n",
      "        ],\n",
      "        \"SupportedContentTypes\": [\n",
      "            \"image/jpeg\",\n",
      "            \"image/png\"\n",
      "        ],\n",
      "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
      "            \"ml.m4.xlarge\",\n",
      "            \"ml.m4.2xlarge\",\n",
      "            \"ml.m4.4xlarge\",\n",
      "            \"ml.m4.10xlarge\",\n",
      "            \"ml.m4.16xlarge\",\n",
      "            \"ml.m5.large\",\n",
      "            \"ml.m5.xlarge\",\n",
      "            \"ml.m5.2xlarge\",\n",
      "            \"ml.m5.4xlarge\",\n",
      "            \"ml.m5.12xlarge\",\n",
      "            \"ml.m5.24xlarge\",\n",
      "            \"ml.c4.xlarge\",\n",
      "            \"ml.c4.2xlarge\",\n",
      "            \"ml.c4.4xlarge\",\n",
      "            \"ml.c4.8xlarge\",\n",
      "            \"ml.c5.xlarge\",\n",
      "            \"ml.c5.2xlarge\",\n",
      "            \"ml.c5.4xlarge\",\n",
      "            \"ml.c5.9xlarge\",\n",
      "            \"ml.c5.18xlarge\",\n",
      "            \"ml.p2.xlarge\",\n",
      "            \"ml.p2.8xlarge\",\n",
      "            \"ml.p2.16xlarge\",\n",
      "            \"ml.p3.2xlarge\",\n",
      "            \"ml.p3.8xlarge\",\n",
      "            \"ml.p3.16xlarge\"\n",
      "        ],\n",
      "        \"SupportedResponseMIMETypes\": [\n",
      "            \"text/plain\"\n",
      "        ],\n",
      "        \"SupportedTransformInstanceTypes\": [\n",
      "            \"ml.m4.xlarge\",\n",
      "            \"ml.m4.2xlarge\",\n",
      "            \"ml.m4.4xlarge\",\n",
      "            \"ml.m4.10xlarge\",\n",
      "            \"ml.m4.16xlarge\",\n",
      "            \"ml.m5.large\",\n",
      "            \"ml.m5.xlarge\",\n",
      "            \"ml.m5.2xlarge\",\n",
      "            \"ml.m5.4xlarge\",\n",
      "            \"ml.m5.12xlarge\",\n",
      "            \"ml.m5.24xlarge\",\n",
      "            \"ml.c4.xlarge\",\n",
      "            \"ml.c4.2xlarge\",\n",
      "            \"ml.c4.4xlarge\",\n",
      "            \"ml.c4.8xlarge\",\n",
      "            \"ml.c5.xlarge\",\n",
      "            \"ml.c5.2xlarge\",\n",
      "            \"ml.c5.4xlarge\",\n",
      "            \"ml.c5.9xlarge\",\n",
      "            \"ml.c5.18xlarge\",\n",
      "            \"ml.p2.xlarge\",\n",
      "            \"ml.p2.8xlarge\",\n",
      "            \"ml.p2.16xlarge\",\n",
      "            \"ml.p3.2xlarge\",\n",
      "            \"ml.p3.8xlarge\",\n",
      "            \"ml.p3.16xlarge\"\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.inference_specification import InferenceSpecification\n",
    "\n",
    "import json\n",
    "\n",
    "modelpackage_inference_specification = InferenceSpecification().get_inference_specification_dict(\n",
    "    ecr_image=image,\n",
    "    supports_gpu=True,\n",
    "    supported_content_types=[\"image/jpeg\", \"image/png\"],\n",
    "    supported_mime_types=[\"text/plain\"])\n",
    "\n",
    "# Specify the model data resulting from the previously completed training job\n",
    "modelpackage_inference_specification[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]=classifier.model_data\n",
    "print(json.dumps(modelpackage_inference_specification, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Specification\n",
    "\n",
    "In order to provide confidence to the sellers (and buyers) that the products work in Amazon SageMaker before listing them on AWS Marketplace, SageMaker needs to perform basic validations. The product can be listed in the AWS Marketplace only if this validation process succeeds. This validation process uses the validation profile and sample data provided by you to run the following validations:\n",
    "\n",
    "* Create a transform job in your account using the above Model to verify your inference image works with SageMaker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ValidationSpecification\": {\n",
      "        \"ValidationProfiles\": [\n",
      "            {\n",
      "                \"ProfileName\": \"ValidationProfile1\",\n",
      "                \"TransformJobDefinition\": {\n",
      "                    \"MaxConcurrentTransforms\": 1,\n",
      "                    \"MaxPayloadInMB\": 10,\n",
      "                    \"TransformInput\": {\n",
      "                        \"CompressionType\": \"None\",\n",
      "                        \"ContentType\": \"image/jpeg\",\n",
      "                        \"DataSource\": {\n",
      "                            \"S3DataSource\": {\n",
      "                                \"S3DataType\": \"S3Prefix\",\n",
      "                                \"S3Uri\": \"s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/batch-inference-input-data/cat1.jpg\"\n",
      "                            }\n",
      "                        },\n",
      "                        \"SplitType\": \"None\"\n",
      "                    },\n",
      "                    \"TransformOutput\": {\n",
      "                        \"Accept\": \"image/jpeg\",\n",
      "                        \"AssembleWith\": \"None\",\n",
      "                        \"KmsKeyId\": \"\",\n",
      "                        \"S3OutputPath\": \"s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/batch-transform-output\"\n",
      "                    },\n",
      "                    \"TransformResources\": {\n",
      "                        \"InstanceCount\": 1,\n",
      "                        \"InstanceType\": \"ml.c4.xlarge\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"ValidationRole\": \"arn:aws:iam::218569190993:role/autogluon-sagemaker-execute-role\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from src.modelpackage_validation_specification import ModelPackageValidationSpecification\n",
    "import json\n",
    "\n",
    "modelpackage_validation_specification = ModelPackageValidationSpecification().get_validation_specification_dict(\n",
    "    validation_role = role,\n",
    "    batch_transform_input = transform_input,\n",
    "    content_type = \"image/jpeg\",\n",
    "    instance_type = \"ml.c4.xlarge\",\n",
    "    output_s3_location = 's3://{}/{}'.format(sess.default_bucket(), common_prefix))\n",
    "\n",
    "print(json.dumps(modelpackage_validation_specification, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now we put all the pieces together in the next cell and create an Amazon SageMaker Model Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"CertifyForMarketplace\": true,\n",
      "    \"InferenceSpecification\": {\n",
      "        \"Containers\": [\n",
      "            {\n",
      "                \"Image\": \"218569190993.dkr.ecr.us-west-2.amazonaws.com/gluoncv-image-classification:latest\",\n",
      "                \"ModelDataUrl\": \"s3://sagemaker-us-west-2-218569190993/output/gluoncv-image-classification-2020-05-04-21-33-26-992/output/model.tar.gz\"\n",
      "            }\n",
      "        ],\n",
      "        \"SupportedContentTypes\": [\n",
      "            \"image/jpeg\",\n",
      "            \"image/png\"\n",
      "        ],\n",
      "        \"SupportedRealtimeInferenceInstanceTypes\": [\n",
      "            \"ml.m4.xlarge\",\n",
      "            \"ml.m4.2xlarge\",\n",
      "            \"ml.m4.4xlarge\",\n",
      "            \"ml.m4.10xlarge\",\n",
      "            \"ml.m4.16xlarge\",\n",
      "            \"ml.m5.large\",\n",
      "            \"ml.m5.xlarge\",\n",
      "            \"ml.m5.2xlarge\",\n",
      "            \"ml.m5.4xlarge\",\n",
      "            \"ml.m5.12xlarge\",\n",
      "            \"ml.m5.24xlarge\",\n",
      "            \"ml.c4.xlarge\",\n",
      "            \"ml.c4.2xlarge\",\n",
      "            \"ml.c4.4xlarge\",\n",
      "            \"ml.c4.8xlarge\",\n",
      "            \"ml.c5.xlarge\",\n",
      "            \"ml.c5.2xlarge\",\n",
      "            \"ml.c5.4xlarge\",\n",
      "            \"ml.c5.9xlarge\",\n",
      "            \"ml.c5.18xlarge\",\n",
      "            \"ml.p2.xlarge\",\n",
      "            \"ml.p2.8xlarge\",\n",
      "            \"ml.p2.16xlarge\",\n",
      "            \"ml.p3.2xlarge\",\n",
      "            \"ml.p3.8xlarge\",\n",
      "            \"ml.p3.16xlarge\"\n",
      "        ],\n",
      "        \"SupportedResponseMIMETypes\": [\n",
      "            \"text/plain\"\n",
      "        ],\n",
      "        \"SupportedTransformInstanceTypes\": [\n",
      "            \"ml.m4.xlarge\",\n",
      "            \"ml.m4.2xlarge\",\n",
      "            \"ml.m4.4xlarge\",\n",
      "            \"ml.m4.10xlarge\",\n",
      "            \"ml.m4.16xlarge\",\n",
      "            \"ml.m5.large\",\n",
      "            \"ml.m5.xlarge\",\n",
      "            \"ml.m5.2xlarge\",\n",
      "            \"ml.m5.4xlarge\",\n",
      "            \"ml.m5.12xlarge\",\n",
      "            \"ml.m5.24xlarge\",\n",
      "            \"ml.c4.xlarge\",\n",
      "            \"ml.c4.2xlarge\",\n",
      "            \"ml.c4.4xlarge\",\n",
      "            \"ml.c4.8xlarge\",\n",
      "            \"ml.c5.xlarge\",\n",
      "            \"ml.c5.2xlarge\",\n",
      "            \"ml.c5.4xlarge\",\n",
      "            \"ml.c5.9xlarge\",\n",
      "            \"ml.c5.18xlarge\",\n",
      "            \"ml.p2.xlarge\",\n",
      "            \"ml.p2.8xlarge\",\n",
      "            \"ml.p2.16xlarge\",\n",
      "            \"ml.p3.2xlarge\",\n",
      "            \"ml.p3.8xlarge\",\n",
      "            \"ml.p3.16xlarge\"\n",
      "        ]\n",
      "    },\n",
      "    \"ModelPackageDescription\": \"Model to perform image classification or extract image features by deep learning\",\n",
      "    \"ModelPackageName\": \"gluoncv-image-classification1588628531\",\n",
      "    \"ValidationSpecification\": {\n",
      "        \"ValidationProfiles\": [\n",
      "            {\n",
      "                \"ProfileName\": \"ValidationProfile1\",\n",
      "                \"TransformJobDefinition\": {\n",
      "                    \"MaxConcurrentTransforms\": 1,\n",
      "                    \"MaxPayloadInMB\": 10,\n",
      "                    \"TransformInput\": {\n",
      "                        \"CompressionType\": \"None\",\n",
      "                        \"ContentType\": \"image/jpeg\",\n",
      "                        \"DataSource\": {\n",
      "                            \"S3DataSource\": {\n",
      "                                \"S3DataType\": \"S3Prefix\",\n",
      "                                \"S3Uri\": \"s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/batch-inference-input-data/cat1.jpg\"\n",
      "                            }\n",
      "                        },\n",
      "                        \"SplitType\": \"None\"\n",
      "                    },\n",
      "                    \"TransformOutput\": {\n",
      "                        \"Accept\": \"image/jpeg\",\n",
      "                        \"AssembleWith\": \"None\",\n",
      "                        \"KmsKeyId\": \"\",\n",
      "                        \"S3OutputPath\": \"s3://sagemaker-us-west-2-218569190993/DEMO-gluoncv-model-zoo/batch-transform-output\"\n",
      "                    },\n",
      "                    \"TransformResources\": {\n",
      "                        \"InstanceCount\": 1,\n",
      "                        \"InstanceType\": \"ml.c4.xlarge\"\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        ],\n",
      "        \"ValidationRole\": \"arn:aws:iam::218569190993:role/autogluon-sagemaker-execute-role\"\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ModelPackageArn': 'arn:aws:sagemaker:us-west-2:218569190993:model-package/gluoncv-image-classification1588628531',\n",
       " 'ResponseMetadata': {'RequestId': '1b6f5e3c-a51f-4895-88dc-b6a8308af03b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '1b6f5e3c-a51f-4895-88dc-b6a8308af03b',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '115',\n",
       "   'date': 'Mon, 04 May 2020 21:42:11 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "model_package_name = \"gluoncv-image-classification\" + str(round(time.time()))\n",
    "create_model_package_input_dict = {\n",
    "    \"ModelPackageName\" : model_package_name,\n",
    "    \"ModelPackageDescription\" : \"Model to perform image classification or extract image features by deep learning\",\n",
    "    \"CertifyForMarketplace\" : True\n",
    "}\n",
    "create_model_package_input_dict.update(modelpackage_inference_specification)\n",
    "create_model_package_input_dict.update(modelpackage_validation_specification)\n",
    "print(json.dumps(create_model_package_input_dict, indent=4, sort_keys=True))\n",
    "\n",
    "smmp.create_model_package(**create_model_package_input_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the ModelPackage \n",
    "\n",
    "The next cell describes the ModelPackage and waits until it reaches a terminal state (Completed or Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n",
      "{'ValidationStatuses': [{'Name': 'ValidationProfile1', 'Status': 'Completed'}], 'ImageScanStatuses': [{'Name': '218569190993.dkr.ecr.us-west-2.amazonaws.com/gluoncv-image-classification@sha256:6da5cb7c722bee70ea8b25355596acb60e417b5cd6c88fc08f54ea00de55b695', 'Status': 'Completed'}]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "while True:\n",
    "    response = smmp.describe_model_package(ModelPackageName=model_package_name)\n",
    "    status = response[\"ModelPackageStatus\"]\n",
    "    print (status)\n",
    "    if (status == \"Completed\" or status == \"Failed\"):\n",
    "        print (response[\"ModelPackageStatusDetails\"])\n",
    "        break\n",
    "    time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Creation Issues\n",
    "\n",
    "Entity creation typically never fails in the synchronous path. However, the validation process can fail for many reasons. If the above Algorithm creation fails, you can investigate the cause for the failure by looking at the \"AlgorithmStatusDetails\" field in the Algorithm object or \"ModelPackageStatusDetails\" field in the ModelPackage object. You can also look for the Training Jobs / Transform Jobs created in your account as part of our validation and inspect their logs for more hints on what went wrong. \n",
    "\n",
    "If all else fails, please contact AWS Customer Support for assistance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## List on AWS Marketplace\n",
    "\n",
    "Next, please go back to the Amazon SageMaker console, click on \"Algorithms\" (or \"Model Packages\") and you'll find the entity you created above. If it was successfully created and validated, you should be able to select the entity and \"Publish new ML Marketplace listing\" from SageMaker console.\n",
    "<img src=\"images/publish-to-marketplace-action.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
